# -*- coding: utf-8 -*-
"""project data preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EKpIcX8lPAtBihelfJgnPZlMy1LW_HB_
"""

# create custom project datasets and dataloaders

from google.colab import drive
drive.mount('/content/drive')

#!pip install torch

#!pip install transformers

#!pip install librosa

# imports
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import json
import os
import torch
import librosa
from PIL import Image
from torchvision import transforms
from transformers import AutoImageProcessor, ResNetForImageClassification, AutoProcessor
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.nn.utils.rnn import pad_sequence
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from transformers import BertModel, BertTokenizer, AutoTokenizer
from transformers import Trainer, TrainingArguments, AdamW

data_dir_real = "./drive/MyDrive/Applied Computer Vision Project/acv-presidential-dataset/real"
data_dir_fake = "./drive/MyDrive/Applied Computer Vision Project/acv-presidential-dataset/fake"

# create dataframe containing audio, text, and screenshot images for each data sample
data = []

# real data
presidents = ['biden', 'trump']
for name in presidents:
  for i in range(1,16):
    audio_file = name + '-real-' + str(i) + '-audio.wav'
    audio_path = os.path.join(data_dir_real, 'audio-files')
    text_file = name + '-real-' + str(i) + '.txt'
    text_path = os.path.join(data_dir_real, 'text-files')
    screenshot_folder_name = name + '-real-' + str(i)
    screenshot_folder_path = os.path.join(data_dir_real, 'screenshots', screenshot_folder_name)
    image_files = os.listdir(screenshot_folder_path)
    sample = {'audio': audio_file, 'text': text_file, 'images': image_files, 'audio_path': audio_path, 'text_path': text_path, 'image_path': screenshot_folder_path, 'label': 0}
    data.append(sample)

# deepfake data
for name in presidents:
  for i in range(1,9):
    audio_file = name + '-fake-' + str(i) + '.wav'
    audio_path = os.path.join(data_dir_fake, 'audio-files')
    text_file = name + '-fake-' + str(i) + '.txt'
    text_path = os.path.join(data_dir_fake, 'text-files')
    screenshot_folder_name = name + '-fake-' + str(i)
    screenshot_folder_path = os.path.join(data_dir_fake, 'screenshots', screenshot_folder_name)
    image_files = os.listdir(screenshot_folder_path)
    sample = {'audio': audio_file, 'text': text_file, 'images': image_files, 'audio_path': audio_path, 'text_path': text_path, 'image_path': screenshot_folder_path, 'label': 1}
    data.append(sample)

data_df = pd.DataFrame(data)

data_df

data_df.loc[1,'image_path']

data_df.loc[1,'text_path']

data_df.loc[1,'audio_path']

# custom dataset

class CustomDataset(Dataset):
  def __init__(self, data_df):
    self.data_df = data_df
    self.image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")

  def __len__(self):
    return len(self.data_df)

  def __getitem__(self, idx):
    audio = self.data_df.loc[idx, 'audio']
    text = self.data_df.loc[idx, 'text']
    images = self.data_df.loc[idx, 'images']
    label = self.data_df.loc[idx, 'label']

    audio_path = self.data_df.loc[idx, 'audio_path']
    full_audio_path = os.path.join(audio_path, audio)
    opened_audio, sample_rate = librosa.load(full_audio_path, sr=None)

    text_path = self.data_df.loc[idx, 'text_path']
    full_text_path = os.path.join(text_path, text)
    with open(full_text_path, 'r') as file:
      opened_text = file.read()

    image_path = self.data_df.loc[idx, 'image_path']
    processed_images = []

    for img in images:
      full_image_path = os.path.join(image_path, img)
      image = Image.open(full_image_path).convert("RGB")
      processed_image = self.image_processor(images=image, return_tensors="pt")
      processed_image = processed_image["pixel_values"]
      processed_images.append(processed_image)

    item = {
        "audio": opened_audio,
        "sample_rate": sample_rate,
        "text": opened_text,
        "images": processed_images,
        "label": label
    }

    return item

# custom collate function

text_tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
audio_processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

def collate_fn(batch):
  audios = [item['audio'] for item in batch]
  sample_rates = [item['sample_rate'] for item in batch]
  texts = [item['text'] for item in batch]
  image_lists = [item['images'] for item in batch]
  labels = [item['label'] for item in batch]

  processed_audios = []
  for audio, sample_rate in zip(audios, sample_rates):
    inputs = audio_processor(audio, sampling_rate=sample_rate, return_tensors="pt")
    processed_audios.append(inputs.input_values.unsqueeze(0))

  processed_audios = torch.stack(processed_audios, dim=0)

  stacked_images = [torch.stack(images, dim=0) for images in image_lists]
  images = torch.stack(stacked_images, dim=0)

  tokenized_texts = text_tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
  tokenized_texts = tokenized_texts['input_ids']

  text_attention_mask = (tokenized_captions != 0).long()

  labels = torch.LongTensor(labels)

  batch_dict = {
      "audios": processed_audios,
      "texts": tokenized_texts,
      "images": images,
      'text_attention_mask': text_attention_mask,
      "labels": labels
  }

  return batch_dict

# create training, validation, and testing dataframes

train_df, test_df = train_test_split(data_df, test_size=0.25, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)

# create training, validation, and testing datasets using custom dataset class

train_dataset = CustomDataset(train_df)
val_dataset = CustomDataset(val_df)
test_dataset = CustomDataset(test_df)

# create training, validation, and testing data loaders

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=0)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=0)

